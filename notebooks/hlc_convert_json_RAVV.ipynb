{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d4863d-fcd5-4a0c-9231-51d63b039699",
   "metadata": {},
   "source": [
    "## Data preparation of RAVV dataset to fine tune the Meta Segment-Anything model\n",
    "\n",
    "We convert the annotations found in the .json file (either bounding boxes or polygons) to arrays (either zipped numpy arrays .npz or .jpg binary masks). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e21a9d-7be7-4201-9102-2d17b1688322",
   "metadata": {},
   "source": [
    "First convert labeled ground-truth segmentations (polygons) into pixel maps and store them as .jpg files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17bda16-e824-4084-985f-853a2d6ca0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/images/'\n",
    "\n",
    "# Specify the directory for storing the masks\n",
    "#mask_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/masks/pixel_masks'\n",
    "mask_directory = '/Volumes/Samsung_USB/pixel_masks_rgb2'\n",
    "# Specify the directory containing the JSON file\n",
    "json_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations'\n",
    "json_filename = 'annotations.json'\n",
    "\n",
    "# Create the mask directory if it doesn't exist\n",
    "os.makedirs(mask_directory, exist_ok=True)\n",
    "\n",
    "# Load the JSON file\n",
    "with open(os.path.join(json_directory, json_filename)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Iterate over each image in the directory\n",
    "for image_info in data.get(\"images\", []):\n",
    "    image_filename = image_info[\"file_name\"]\n",
    "    image_width = image_info[\"width\"]\n",
    "    image_height = image_info[\"height\"]\n",
    "\n",
    "    # Create a blank binary mask with the same dimensions as the image\n",
    "    #binary_mask = Image.new('L', (image_width, image_height), 0)  # 'L' for 8-bit pixels, black and white\n",
    "    binary_mask = Image.new('RGB', (image_width, image_height), (0, 0, 0))  # 'RGB' for 3-channel color image\n",
    "\n",
    "    # Find the corresponding annotations for the image\n",
    "    image_id = image_info[\"id\"]\n",
    "    annotations = [ann for ann in data.get(\"annotations\", []) if ann[\"image_id\"] == image_id]\n",
    "\n",
    "\n",
    "    # Draw polygons on the mask image\n",
    "    for annotation in annotations:\n",
    "        segmentation = annotation.get(\"segmentation\")\n",
    "        if segmentation is not None:\n",
    "            for segment in segmentation:\n",
    "                # Flatten the segment coordinates into a 1D list\n",
    "                flattened_segment = [int(coord) for coord in segment]\n",
    "                # Reshape the flattened segment into pairs of (x, y) coordinates\n",
    "                #coordinates = [(flattened_segment[i], flattened_segment[i + 1]) for i in range(0, len(flattened_segment), 2)]\n",
    "                coordinates = [(flattened_segment[i + 1], flattened_segment[i]) for i in range(0, len(flattened_segment), 2)]\n",
    "                draw = ImageDraw.Draw(binary_mask)\n",
    "                #draw.polygon(coordinates, outline=255, fill=255)\n",
    "                draw.polygon(coordinates, outline=(255, 255, 255), fill=(255, 255, 255))\n",
    "\n",
    "\n",
    "    # Invert the binary mask (invert black and white regions)\n",
    "    inverted_mask = Image.eval(binary_mask, lambda x: 255 - x)\n",
    "\n",
    "    # Save the binary mask as JPEG in the mask directory\n",
    "    mask_filename = os.path.splitext(image_filename)[0] + '.jpg'\n",
    "    mask_path = os.path.join(mask_directory, mask_filename)\n",
    "    inverted_mask.save(mask_path)\n",
    "    \n",
    "   \n",
    "# Save the binary mask as JPEG in the mask directory\n",
    "#image_filename_lower = image_filename.lower()\n",
    "if image_filename.endswith('.JPG') or image_filename.endswith('.JPEG') or image_filename.endswith('.PNG'):\n",
    "    mask_filename = os.path.splitext(image_filename)[0] + '.JPG'\n",
    "else:\n",
    "    mask_filename = os.path.splitext(image_filename)[0] + '.jpg'\n",
    "\n",
    "mask_path = os.path.join(mask_directory, mask_filename)\n",
    "inverted_mask.save(mask_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b160db0-1ce4-4a0e-8df4-aee5a74faa3c",
   "metadata": {},
   "source": [
    "Same thing for bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786371d0-d5a0-47be-8341-643c1cdf0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/images'\n",
    "\n",
    "# Specify the directory for storing the masks\n",
    "mask_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/bb_masks'\n",
    "\n",
    "# Specify the directory containing the JSON file\n",
    "json_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations'\n",
    "json_filename = 'annotations.json'\n",
    "\n",
    "# Create the mask directory if it doesn't exist\n",
    "#os.makedirs(mask_directory, exist_ok=True)\n",
    "\n",
    "# Load the JSON file\n",
    "with open(os.path.join(json_directory, json_filename)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Iterate over each image in the directory\n",
    "for image_info in data.get(\"images\", []):\n",
    "    image_filename = image_info[\"file_name\"]\n",
    "    image_width = image_info[\"width\"]\n",
    "    image_height = image_info[\"height\"]\n",
    "\n",
    "    # Create a blank binary mask with the same dimensions as the image\n",
    "    binary_mask = Image.new('L', (image_width, image_height), 0)  # 'L' for 8-bit pixels, black and white\n",
    "\n",
    "    # Find the corresponding annotations for the image\n",
    "    image_id = image_info[\"id\"]\n",
    "    annotations = [ann for ann in data.get(\"annotations\", []) if ann[\"image_id\"] == image_id]\n",
    "\n",
    "    # Draw bounding boxes on the mask image\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation.get(\"bbox\")\n",
    "        if bbox is not None and len(bbox) == 4:\n",
    "            x, y, w, h = bbox\n",
    "            x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)\n",
    "            draw = ImageDraw.Draw(binary_mask)\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], fill=255)\n",
    "\n",
    "    # Invert the binary mask (invert black and white regions)\n",
    "    inverted_mask = Image.eval(binary_mask, lambda x: 255 - x)\n",
    "\n",
    "    # Save the inverted binary mask as JPEG in the mask directory\n",
    "    mask_filename = os.path.splitext(image_filename)[0] + '_mask_bw.jpg'\n",
    "    mask_path = os.path.join(mask_directory, mask_filename)\n",
    "    inverted_mask.save(mask_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61c09fb-27d9-484d-9a6c-93230aefcd6f",
   "metadata": {},
   "source": [
    "The .jpg images can be used to inspect the masks and compare them to the locations in the images. However, we caution against using all images and masks in the format provided for two reasons:\n",
    "\n",
    "First: there are a few instances, especially in the files 'GOPRO..'' where the saved image is either inverted or rotated with respect to the coordinates of the mask. \n",
    "\n",
    "Second: this method of reading in the bounding boxes into the program to fine tune sam is only valid for images where the bounding boxes do not overlap -- in other words where there are relatively few and well-separated annotated objects. \n",
    "\n",
    "We provide a log file where we have indicated whether the image is rotated or mirrored (First issue) or crowded (second issue). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ddfe4b-6f6d-46a5-8fb2-e24c1f491ef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0a729ff-8ab0-46ab-a7b4-82cde340966e",
   "metadata": {},
   "source": [
    "To avoid overlapping bounding boxes, we provide the masks as zipped numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78397435-5756-48a3-b94f-67f7841f8645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/images'\n",
    "\n",
    "# Specify the directory for storing the masks\n",
    "mask_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/masks/pixel_zipped'\n",
    "\n",
    "# Specify the directory containing the JSON file\n",
    "json_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations'\n",
    "json_filename = 'annotations.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(os.path.join(json_directory, json_filename)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Iterate over each image in the directory\n",
    "for image_info in data.get(\"images\", []):\n",
    "    image_filename = image_info[\"file_name\"]\n",
    "    image_width = image_info[\"width\"]\n",
    "    image_height = image_info[\"height\"]\n",
    "\n",
    "    # Find the corresponding annotations for the image\n",
    "    image_id = image_info[\"id\"]\n",
    "    annotations = [ann for ann in data.get(\"annotations\", []) if ann[\"image_id\"] == image_id]\n",
    "\n",
    "    # Create an empty array to store the masks\n",
    "    number_masks = len(annotations)\n",
    "    masks = np.zeros((number_masks, 1, image_height, image_width), dtype=bool)\n",
    "\n",
    "    # Draw polygons on the mask image and store them in the masks array\n",
    "    for idx, annotation in enumerate(annotations):\n",
    "        segmentation = annotation.get(\"segmentation\")\n",
    "        if segmentation is not None:\n",
    "            mask = Image.new('L', (image_width, image_height), 0)\n",
    "            draw = ImageDraw.Draw(mask)\n",
    "            for segment in segmentation:\n",
    "                flattened_segment = [int(coord) for coord in segment]\n",
    "                coordinates = [(flattened_segment[i + 1], flattened_segment[i]) for i in range(0, len(flattened_segment), 2)]\n",
    "                draw.polygon(coordinates, outline=1, fill=1)\n",
    "            masks[idx, 0, :, :] = np.array(mask)\n",
    "\n",
    "    # Create the output file path for the current image\n",
    "    file_out = os.path.join(mask_directory, os.path.splitext(image_filename)[0] + '.npz')\n",
    "\n",
    "    # Save the masks as a single .npz file\n",
    "    np.savez_compressed(file_out, masks=masks)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f45ae0b-24d4-4fb7-8822-0c0554e21f12",
   "metadata": {},
   "source": [
    "And the same for the bounding boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674c765e-9bbe-487e-84de-2e6fbe4e6073",
   "metadata": {},
   "source": [
    "Here we can check the influence of data type on size. We check this because the fine-tuning algorithm is limited by the required large data set and resultant memory needed. We can check if boolean arrays will help allow us to include more images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0aa6937a-99b3-49a2-8b4f-af41282b0b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size with dtype=np.uint8: 10128 bytes\n",
      "File size with dtype=np.uint16: 20128 bytes\n",
      "File size with dtype=np.float32: 40128 bytes\n",
      "Memory size with dtype=np.bool: 10000 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/b6r_0sgs13v067m_scmh41jw0000gn/T/ipykernel_6854/1361162628.py:19: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  arr = np.zeros((100, 100), dtype=np.bool)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.zeros((100, 100), dtype=np.uint8)\n",
    "file_path_uint8 = \"array_uint8.npy\"\n",
    "np.save(file_path_uint8, arr)\n",
    "print(f\"File size with dtype=np.uint8: {os.path.getsize(file_path_uint8)} bytes\")\n",
    "\n",
    "arr = np.zeros((100, 100), dtype=np.uint16)\n",
    "file_path_uint16 = \"array_uint16.npy\"\n",
    "np.save(file_path_uint16, arr)\n",
    "print(f\"File size with dtype=np.uint16: {os.path.getsize(file_path_uint16)} bytes\")\n",
    "\n",
    "arr = np.zeros((100, 100), dtype=np.float32)\n",
    "file_path_float32 = \"array_float32.npy\"\n",
    "np.save(file_path_float32, arr)\n",
    "print(f\"File size with dtype=np.float32: {os.path.getsize(file_path_float32)} bytes\")\n",
    "\n",
    "\n",
    "arr = np.zeros((100, 100), dtype=np.bool)\n",
    "print(f\"Memory size with dtype=np.bool: {arr.nbytes} bytes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa863a-0bf6-4c86-bc93-1d57950119cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to convert the .json files to .jpgs for the bounding boxes\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/images'\n",
    "\n",
    "# Specify the directory for storing the masks\n",
    "mask_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/bb_masks'\n",
    "\n",
    "# Specify the directory containing the JSON file\n",
    "json_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations'\n",
    "json_filename = 'annotations.json'\n",
    "\n",
    "# Create the mask directory if it doesn't exist\n",
    "#os.makedirs(mask_directory, exist_ok=True)\n",
    "\n",
    "# Load the JSON file\n",
    "with open(os.path.join(json_directory, json_filename)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Iterate over each image in the directory\n",
    "for image_info in data.get(\"images\", []):\n",
    "    image_filename = image_info[\"file_name\"]\n",
    "    image_width = image_info[\"width\"]\n",
    "    image_height = image_info[\"height\"]\n",
    "\n",
    "    # Create a blank binary mask with the same dimensions as the image\n",
    "    binary_mask = Image.new('L', (image_width, image_height), 0)  # 'L' for 8-bit pixels, black and white\n",
    "\n",
    "    # Find the corresponding annotations for the image\n",
    "    image_id = image_info[\"id\"]\n",
    "    annotations = [ann for ann in data.get(\"annotations\", []) if ann[\"image_id\"] == image_id]\n",
    "\n",
    "    # Draw bounding boxes on the mask image\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation.get(\"bbox\")\n",
    "        if bbox is not None and len(bbox) == 4:\n",
    "            x, y, w, h = bbox\n",
    "            x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)\n",
    "            draw = ImageDraw.Draw(binary_mask)\n",
    "            draw.rectangle([(x1, y1), (x2, y2)], fill=255)\n",
    "\n",
    "    # Invert the binary mask (invert black and white regions)\n",
    "    inverted_mask = Image.eval(binary_mask, lambda x: 255 - x)\n",
    "\n",
    "    # Save the inverted binary mask as JPEG in the mask directory\n",
    "    mask_filename = os.path.splitext(image_filename)[0] + '_mask_bw.jpg'\n",
    "    mask_path = os.path.join(mask_directory, mask_filename)\n",
    "    inverted_mask.save(mask_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ecf0d7-c05d-4f19-b7db-a928eb0df69d",
   "metadata": {},
   "source": [
    "From the visual inspection of the files created, we can see that some of the images are either crowded with overlapping bounding boxes, or else need to be inverted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26aa5610-7bf7-44b6-b9e7-bd61a1febbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/images'\n",
    "\n",
    "# Specify the directory for storing the masks and bounding boxes\n",
    "output_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/masks/bb_zipped'\n",
    "\n",
    "# Specify the directory containing the JSON file\n",
    "json_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations'\n",
    "json_filename = 'annotations.json'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(os.path.join(json_directory, json_filename)) as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# Iterate over each image in the directory\n",
    "for image_info in data.get(\"images\", []):\n",
    "    image_filename = image_info[\"file_name\"]\n",
    "    image_width = image_info[\"width\"]\n",
    "    image_height = image_info[\"height\"]\n",
    "\n",
    "    # Find the corresponding annotations for the image\n",
    "    image_id = image_info[\"id\"]\n",
    "    annotations = [ann for ann in data.get(\"annotations\", []) if ann[\"image_id\"] == image_id]\n",
    "\n",
    "    # Create an empty array to store the bounding boxes\n",
    "    number_boxes = len(annotations)\n",
    "    boxes = np.zeros((number_boxes, 1, image_height, image_width))\n",
    "\n",
    "    # Draw bounding boxes on the mask image and store them in the boxes array\n",
    "    for idx, annotation in enumerate(annotations):\n",
    "        bbox = annotation.get(\"bbox\")\n",
    "        if bbox is not None and len(bbox) == 4:\n",
    "            x, y, w, h = bbox\n",
    "            x1, y1, x2, y2 = int(x), int(y), int(x + w), int(y + h)\n",
    "            mask = np.zeros((image_height, image_width), dtype=np.uint8)\n",
    "            mask[y1:y2, x1:x2] = 255\n",
    "            boxes[idx, 0, :, :] = mask\n",
    "\n",
    "    # Create the output file path for the current image\n",
    "    file_out = os.path.join(output_directory, os.path.splitext(image_filename)[0] + '.npz')\n",
    "\n",
    "    # Save the bounding boxes as a single .npz file\n",
    "    np.savez_compressed(file_out, boxes=boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c863b33c-076e-40c1-8ecf-ec31d8cd56a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Read the CSV file into a list of lists\n",
    "my_file='/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/logs/uavwaste_notes.csv'\n",
    "data = []\n",
    "with open(my_file, 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        data.append(row)\n",
    "\n",
    "# Access the values in the list of lists\n",
    "file_list =[row[0] for row in data]\n",
    "status = [row[1] if len(row) > 1 else None for row in data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fd66c5f8-ce81-4883-abd0-1a6f0aec0b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['camera_img_0.jpg', 'camera_img_1.jpg', 'camera_img_2.jpg']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_files1 = [file for file, stat in zip(file_list, status) if stat == 'XY']\n",
    "#filtered_filess\n",
    "\n",
    "filtered_files2= [file for file, stat in zip(file_list, status) if stat == 'crowded']\n",
    "#filtered_files2\n",
    "\n",
    "filtered_files3= [file for file, stat in zip(file_list, status) if stat == 'L90']\n",
    "filtered_files3\n",
    "\n",
    "#we can use this information to decide which images to use and how to transform them. if XY, we will transpose the original image file in x and y. If crowded, we will not work with them as binary masks in jpg format. If L90, we will rotate by 90 degrees to the right. .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7e276561-6a4f-4430-8edf-09ddf54047f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GOPR0021.JPG',\n",
       " 'GOPR0022.JPG',\n",
       " 'GOPR0023.JPG',\n",
       " 'GOPR0026.JPG',\n",
       " 'GOPR0027.JPG',\n",
       " 'GOPR0028.JPG',\n",
       " 'GOPR0030.JPG',\n",
       " 'GOPR0032.JPG',\n",
       " 'GOPR0034.JPG',\n",
       " 'GOPR0035.JPG',\n",
       " 'GOPR0036.JPG',\n",
       " 'GOPR0037.JPG',\n",
       " 'GOPR0038.JPG',\n",
       " 'GOPR0039.JPG',\n",
       " 'GOPR0043.JPG',\n",
       " 'GOPR0044.JPG',\n",
       " 'GOPR0046.JPG',\n",
       " 'GOPR0049.JPG',\n",
       " 'GOPR0050.JPG',\n",
       " 'GOPR0051.JPG',\n",
       " 'GOPR0053.JPG',\n",
       " 'GOPR0054.JPG',\n",
       " 'GOPR0055.JPG']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_files1 = [file for file, stat in zip(file_list, status) if stat == 'XY']\n",
    "filtered_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8bf5baec-2aae-49d0-8db4-54c9d1449ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Images: 772\n",
      "Number of Annotations: 3718\n",
      "Number of Unique Categories: 1\n",
      "Number of Non-Crowd Annotations: 3718\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON file\n",
    "fname = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations/annotations.json'\n",
    "with open(fname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize counters\n",
    "num_images = len(data[\"images\"])\n",
    "num_annotations = len(data[\"annotations\"])\n",
    "\n",
    "# Count unique category IDs\n",
    "unique_categories = set()\n",
    "for annotation in data[\"annotations\"]:\n",
    "    unique_categories.add(annotation[\"category_id\"])\n",
    "num_categories = len(unique_categories)\n",
    "\n",
    "# Count non-crowd annotations\n",
    "num_non_crowd_annotations = sum(1 for annotation in data[\"annotations\"] if annotation[\"iscrowd\"] == 0)\n",
    "\n",
    "# Print the basic properties\n",
    "print(\"Number of Images:\", num_images)\n",
    "print(\"Number of Annotations:\", num_annotations)\n",
    "print(\"Number of Unique Categories:\", num_categories)\n",
    "print(\"Number of Non-Crowd Annotations:\", num_non_crowd_annotations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ebc0f3-1373-4a81-a2a6-226608c433e1",
   "metadata": {},
   "source": [
    "apparently they have not stored any litter type labels in the json annotation files. Moreover, they do not consider any of the images crowded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8826423b-2211-4bcb-b4fd-5e0e4669e2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/b6r_0sgs13v067m_scmh41jw0000gn/T/ipykernel_6854/2209858291.py:20: DeprecationWarning: FLIP_LEFT_RIGHT is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_LEFT_RIGHT instead.\n",
      "  flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)\n",
      "/var/folders/3c/b6r_0sgs13v067m_scmh41jw0000gn/T/ipykernel_6854/2209858291.py:20: DeprecationWarning: FLIP_TOP_BOTTOM is deprecated and will be removed in Pillow 10 (2023-07-01). Use Transpose.FLIP_TOP_BOTTOM instead.\n",
      "  flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "# Specify the directory containing the images\n",
    "image_directory = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/images'\n",
    "\n",
    "# Get the filenames of the filtered files\n",
    "filtered_files1 = [file for file, stat in zip(file_list, status) if stat == 'XY']\n",
    "\n",
    "# Iterate over each image filename in the filtered_files\n",
    "for image_filename in filtered_files:\n",
    "    # Read the original image\n",
    "    image_path = os.path.join(image_directory, image_filename)\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Flip the image along the X and Y axes\n",
    "    flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT).transpose(Image.FLIP_TOP_BOTTOM)\n",
    "    \n",
    "\n",
    "    # Save the flipped image as a new JPEG\n",
    "    #flipped_filename = os.path.splitext(image_filename)[0] + '_flipped.jpg'\n",
    "    #flipped_path = os.path.join(image_directory, flipped_filename)\n",
    "    #flipped_image.save(flipped_path)\n",
    "    \n",
    "       \n",
    "#display(flipped_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc153b4-0f83-4d56-9d33-6123aa86ab5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('unable to open database file')).History will not be written to the database.\n",
      "Number of Images: 772\n",
      "Number of Annotations: 3718\n",
      "Number of Unique Categories: 1\n",
      "Number of Non-Crowd Annotations: 3718\n",
      "Number of Bounding Boxes: 3718\n",
      "Number of Segmentations: 3718\n",
      "Bounding Boxes and Segmentations Match: True\n"
     ]
    }
   ],
   "source": [
    "# Load the JSON file\n",
    "fname = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/UAVVaste/annotations/annotations.json'\n",
    "with open(fname, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Initialize counters\n",
    "num_images = len(data[\"images\"])\n",
    "num_annotations = len(data[\"annotations\"])\n",
    "\n",
    "# Count unique category IDs\n",
    "unique_categories = set()\n",
    "for annotation in data[\"annotations\"]:\n",
    "    unique_categories.add(annotation[\"category_id\"])\n",
    "num_categories = len(unique_categories)\n",
    "\n",
    "# Count non-crowd annotations\n",
    "num_non_crowd_annotations = sum(1 for annotation in data[\"annotations\"] if annotation[\"iscrowd\"] == 0)\n",
    "\n",
    "# Check if number of bounding boxes matches number of segmentations\n",
    "num_bounding_boxes = sum(\"bbox\" in annotation for annotation in data[\"annotations\"])\n",
    "num_segmentations = sum(\"segmentation\" in annotation for annotation in data[\"annotations\"])\n",
    "matching_bbox_segmentation = num_bounding_boxes == num_segmentations\n",
    "\n",
    "# Print the basic properties\n",
    "print(\"Number of Images:\", num_images)\n",
    "print(\"Number of Annotations:\", num_annotations)\n",
    "print(\"Number of Unique Categories:\", num_categories)\n",
    "print(\"Number of Non-Crowd Annotations:\", num_non_crowd_annotations)\n",
    "print(\"Number of Bounding Boxes:\", num_bounding_boxes)\n",
    "print(\"Number of Segmentations:\", num_segmentations)\n",
    "print(\"Bounding Boxes and Segmentations Match:\", matching_bbox_segmentation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6722a7-fdc7-478b-a411-956c32e59559",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
