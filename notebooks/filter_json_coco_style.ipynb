{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0bbbd09-6983-4f10-bcdd-9d6dbf0c2e0a",
   "metadata": {},
   "source": [
    "## Example notebook to work with json files in the coco-like format. \n",
    "Here we compare a file with image, annotation, and category information with one containing a train-test-split specification for the dataset. We then write out setparate json files that have been filtered according to which group to which the images belong. The files have been downloaded from the UAVV dataset and correspond to publicly available images. https://uavvaste.github.io . \n",
    "#H.L.C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a05f8f8f-58f7-4836-85bc-f30999584f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Define complete paths to the input and output JSON files\n",
    "#annotations_json_path = '/path/to/input/annotations.json'\n",
    "#split_json_path = '/path/to/input/train_val_test_distribution_file.json'\n",
    "#output_json_path = '/path/to/output/train_annotations.json'\n",
    "\n",
    "# Define complete paths to the input and output JSON files\n",
    "annotations_json_path = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/annotations/annotations.json'\n",
    "split_json_path = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/annotations/train_val_test_distribution_file_lc.json'\n",
    "#output_json_path = '/Users/capelo/Desktop/constructor/final_project/fine_tune_sam/UAVVaste/branch_UAVVaste/UAVVaste/annotations/train_annotations.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be1ff64e-e9e5-475e-9c90-e960934a3f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train_val_test_distribution_file.json to get the list of train images\n",
    "with open(split_json_path) as train_val_test_file:\n",
    "    train_val_test_data = json.load(train_val_test_file)\n",
    "\n",
    "# Get the list of train images from the train split information\n",
    "train_images = train_val_test_data.get(\"train\", [])\n",
    "# Get the list of train images from the train split information\n",
    "test_images = train_val_test_data.get(\"test\", [])\n",
    "# Get the list of train images from the train split information\n",
    "val_images = train_val_test_data.get(\"val\", [])\n",
    "\n",
    "# Load the annotations.json file\n",
    "with open(annotations_json_path) as annotations_file:\n",
    "    annotations_data = json.load(annotations_file)\n",
    "\n",
    "# Filter the annotations based on the test split information\n",
    "test_annotations = [ann for ann in annotations_data['annotations'] if annotations_data['images'][ann['image_id']]['file_name'] in test_images]\n",
    "train_annotations = [ann for ann in annotations_data['annotations'] if annotations_data['images'][ann['image_id']]['file_name'] in train_images]\n",
    "val_annotations = [ann for ann in annotations_data['annotations'] if annotations_data['images'][ann['image_id']]['file_name'] in val_images]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ea4d6e7-5f6b-4c12-9679-3e96cc7d493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### here check how you are defining the annotations data for each category... repeat for train and val \n",
    "\n",
    "# Get the unique image IDs from the test annotations\n",
    "test_image_ids = {ann['image_id'] for ann in test_annotations}\n",
    "train_image_ids = {ann['image_id'] for ann in train_annotations}\n",
    "val_image_ids = {ann['image_id'] for ann in val_annotations}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5f0d709-ec92-451b-b01b-14a13aae3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the images and categories based on the test image IDs\n",
    "test_images_info = [img_info for img_info in annotations_data['images'] if img_info['id'] in test_image_ids]\n",
    "test_categories = annotations_data['categories']\n",
    "\n",
    "# Filter the images and categories based on the train image IDs\n",
    "train_images_info = [img_info for img_info in annotations_data['images'] if img_info['id'] in train_image_ids]\n",
    "train_categories = annotations_data['categories']\n",
    "\n",
    "# Filter the images and categories based on the val image IDs\n",
    "val_images_info = [img_info for img_info in annotations_data['images'] if img_info['id'] in val_image_ids]\n",
    "val_categories = annotations_data['categories']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8912388a-1efb-40c1-8261-b96892b88b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reduced annotations data with test images and test annotations\n",
    "test_reduced_annotations_data = {\n",
    "    \"images\": test_images_info,\n",
    "    \"categories\": test_categories,\n",
    "    \"annotations\": test_annotations\n",
    "}\n",
    "\n",
    "# Save the reduced_annotations_data as a JSON file in a COCO-like structure with indentation\n",
    "with open('test_reduced_annotations.json', 'w') as reduced_annotations_file:\n",
    "    json.dump(test_reduced_annotations_data, reduced_annotations_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23af542a-a0e3-444e-8ac2-8519769379b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reduced annotations data with train images and test annotations\n",
    "train_reduced_annotations_data = {\n",
    "    \"images\": train_images_info,\n",
    "    \"categories\": train_categories,\n",
    "    \"annotations\": train_annotations\n",
    "}\n",
    "\n",
    "# Save the reduced_annotations_data as a JSON file in a COCO-like structure with indentation\n",
    "with open('train_reduced_annotations.json', 'w') as reduced_annotations_file:\n",
    "    json.dump(train_reduced_annotations_data, reduced_annotations_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e22f5738-5908-4e04-8192-ce3d8b279e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reduced annotations data with val images and test annotations\n",
    "val_reduced_annotations_data = {\n",
    "    \"images\": val_images_info,\n",
    "    \"categories\": val_categories,\n",
    "    \"annotations\": val_annotations\n",
    "}\n",
    "\n",
    "# Save the reduced_annotations_data as a JSON file in a COCO-like structure with indentation\n",
    "with open('val_reduced_annotations.json', 'w') as reduced_annotations_file:\n",
    "    json.dump(val_reduced_annotations_data, reduced_annotations_file, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9cc38-3269-4e22-a5bf-61043efe6580",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
